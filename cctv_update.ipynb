{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554ee821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonClassifier:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize person classification system\n",
    "        Note: In production, you would load actual gender and age classification models here\n",
    "        \"\"\"\n",
    "        self.gender_model = None\n",
    "        self.age_model = None\n",
    "        # self.load_models()  # Uncomment when you have actual models\n",
    "        \n",
    "        # For demo purposes - we'll use simple heuristics\n",
    "        self.adult_height_threshold = 150  # pixels, adjust based on your camera setup\n",
    "        \n",
    "    def load_models(self):\n",
    "        \"\"\"Load gender and age classification models\"\"\"\n",
    "        # Placeholder for actual model loading\n",
    "        # You can use pre-trained models like:\n",
    "        # - Gender classification: https://github.com/yu4u/age-gender-estimation\n",
    "        # - Age estimation models\n",
    "        try:\n",
    "            # Example of how you might load models:\n",
    "            # self.gender_model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "            # self.age_model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading person classification models: {e}\")\n",
    "    \n",
    "    def classify_person(self, frame, bbox):\n",
    "        \"\"\"\n",
    "        Classify person's gender and age group\n",
    "        \n",
    "        Args:\n",
    "            frame: Complete frame\n",
    "            bbox: Bounding box coordinates [x1, y1, x2, y2]\n",
    "            \n",
    "        Returns:\n",
    "            dict: {'gender': 'male/female', 'age_group': 'kid/adult', 'final_class': 'male/female/kid'}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Extract person ROI\n",
    "            x1, y1, x2, y2 = [int(coord) for coord in bbox]\n",
    "            \n",
    "            # Ensure coordinates are within frame bounds\n",
    "            h, w = frame.shape[:2]\n",
    "            x1, y1 = max(0, x1), max(0, y1)\n",
    "            x2, y2 = min(w, x2), min(h, y2)\n",
    "            \n",
    "            if x2 <= x1 or y2 <= y1:\n",
    "                return self._get_random_classification()\n",
    "            \n",
    "            person_roi = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if person_roi.size == 0:\n",
    "                return self._get_random_classification()\n",
    "            \n",
    "            # Get person height in pixels\n",
    "            person_height = y2 - y1\n",
    "            \n",
    "            # Simple heuristic for age classification\n",
    "            is_kid = self._classify_age_simple(person_height, person_roi)\n",
    "            \n",
    "            # Gender classification (simplified for demo)\n",
    "            gender = self._classify_gender_simple(person_roi)\n",
    "            \n",
    "            # Final classification\n",
    "            if is_kid:\n",
    "                final_class = 'kid'\n",
    "            else:\n",
    "                final_class = gender\n",
    "                \n",
    "            return {\n",
    "                'gender': gender,\n",
    "                'age_group': 'kid' if is_kid else 'adult',\n",
    "                'final_class': final_class\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in person classification: {e}\")\n",
    "            return self._get_random_classification()\n",
    "    \n",
    "    def _classify_age_simple(self, height, person_roi):\n",
    "        \"\"\"Simple height-based age classification\"\"\"\n",
    "        # Basic heuristic: if height is below threshold, classify as kid\n",
    "        return height < self.adult_height_threshold\n",
    "    \n",
    "    def _classify_gender_simple(self, person_roi):\n",
    "        \"\"\"Simple gender classification (placeholder)\"\"\"\n",
    "        # In production, replace with actual gender classification model\n",
    "        # For demo, using a random approach\n",
    "        import random\n",
    "        return 'male' if random.random() > 0.5 else 'female'\n",
    "    \n",
    "    def _get_random_classification(self):\n",
    "        \"\"\"Fallback random classification\"\"\"\n",
    "        import random\n",
    "        choices = ['male', 'female', 'kid']\n",
    "        weights = [0.4, 0.4, 0.2]\n",
    "        final_class = random.choices(choices, weights=weights)[0]\n",
    "        \n",
    "        if final_class == 'kid':\n",
    "            return {'gender': 'unknown', 'age_group': 'kid', 'final_class': 'kid'}\n",
    "        else:\n",
    "            return {'gender': final_class, 'age_group': 'adult', 'final_class': final_class}\n",
    "\n",
    "class CCTVDetection:\n",
    "    def __init__(self, rtsp_url):\n",
    "        \"\"\"\n",
    "        Initialize the CCTV detection system with person classification\n",
    "        \"\"\"\n",
    "        self.rtsp_url = rtsp_url\n",
    "        self.cap = None\n",
    "        self.model = None\n",
    "        self.person_classifier = PersonClassifier()\n",
    "        self.device = None\n",
    "        \n",
    "        self.initialize_model()\n",
    "        \n",
    "        # Define color mappings for different classes\n",
    "        self.colors = {\n",
    "            'car': (0, 255, 0),        # Green\n",
    "            'bike': (255, 0, 0),       # Blue\n",
    "            'cycle': (0, 255, 255),    # Yellow\n",
    "            'motorcycle': (255, 0, 255), # Magenta\n",
    "            'male': (0, 165, 255),     # Orange\n",
    "            'female': (255, 192, 203), # Pink\n",
    "            'kid': (255, 255, 0)       # Cyan\n",
    "        }\n",
    "        \n",
    "        # Class mappings\n",
    "        self.vehicle_classes = ['car', 'bike', 'cycle', 'motorcycle']\n",
    "        self.person_classes = ['male', 'female', 'kid']\n",
    "        \n",
    "        # Statistics tracking\n",
    "        self.frame_count = 0\n",
    "        self.detection_stats = {\n",
    "            'total_vehicles': 0,\n",
    "            'total_persons': 0,\n",
    "            'vehicle_counts': {v: 0 for v in self.vehicle_classes},\n",
    "            'person_counts': {p: 0 for p in self.person_classes}\n",
    "        }\n",
    "        \n",
    "    def initialize_model(self):\n",
    "        \"\"\"Initialize YOLO model for object detection\"\"\"\n",
    "        try:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            print(f\"Using device: {self.device}\")\n",
    "            \n",
    "            # Load YOLOv8 model\n",
    "            self.model = YOLO('yolov8n.pt')\n",
    "            print(\"YOLO model loaded successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading YOLO model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def map_yolo_to_custom_classes(self, class_id, class_name, bbox=None, frame=None):\n",
    "        \"\"\"\n",
    "        Map YOLO classes to our custom categories\n",
    "        \n",
    "        Args:\n",
    "            class_id: YOLO class ID\n",
    "            class_name: YOLO class name\n",
    "            bbox: Bounding box coordinates (for person classification)\n",
    "            frame: Original frame (for person classification)\n",
    "        \"\"\"\n",
    "        # YOLO COCO dataset class mappings\n",
    "        class_mappings = {\n",
    "            # Vehicles\n",
    "            2: ('car', True, False),        # car\n",
    "            3: ('motorcycle', True, False), # motorcycle\n",
    "            5: ('car', True, False),        # bus\n",
    "            7: ('car', True, False),        # truck\n",
    "            1: ('cycle', True, False),      # bicycle\n",
    "            \n",
    "            # Persons\n",
    "            0: ('person', False, True)      # person\n",
    "        }\n",
    "        \n",
    "        if class_id in class_mappings:\n",
    "            mapped_class, is_vehicle, is_person = class_mappings[class_id]\n",
    "            \n",
    "            if is_person and bbox is not None and frame is not None:\n",
    "                # Use person classifier for detailed classification\n",
    "                person_info = self.person_classifier.classify_person(frame, bbox)\n",
    "                return person_info['final_class'], False, True\n",
    "            else:\n",
    "                return mapped_class, is_vehicle, is_person\n",
    "        \n",
    "        return None, False, False\n",
    "    \n",
    "    def connect_to_camera(self):\n",
    "        \"\"\"Connect to RTSP stream\"\"\"\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(self.rtsp_url)\n",
    "            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "            \n",
    "            if not self.cap.isOpened():\n",
    "                print(\"Error: Could not connect to camera\")\n",
    "                return False\n",
    "            \n",
    "            # Get camera info\n",
    "            width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "            \n",
    "            print(f\"Successfully connected to CCTV camera: {width}x{height} at {fps:.2f} FPS\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to camera: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process a single frame for detection\"\"\"\n",
    "        if frame is None:\n",
    "            return frame, {}\n",
    "        \n",
    "        # Run YOLO inference\n",
    "        results = self.model(frame, verbose=False)\n",
    "        \n",
    "        detection_data = self.parse_detections(results, frame)\n",
    "        processed_frame = self.draw_detections(frame, detection_data)\n",
    "        \n",
    "        # Update statistics\n",
    "        self.update_statistics(detection_data)\n",
    "        \n",
    "        return processed_frame, detection_data\n",
    "    \n",
    "    def parse_detections(self, results, frame):\n",
    "        \"\"\"Parse YOLO detection results\"\"\"\n",
    "        detection_data = {cls: 0 for cls in self.vehicle_classes + self.person_classes}\n",
    "        detections = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    # Get box coordinates\n",
    "                    xyxy = box.xyxy[0].cpu().numpy()\n",
    "                    confidence = box.conf[0].cpu().numpy()\n",
    "                    class_id = int(box.cls[0].cpu().numpy())\n",
    "                    class_name = result.names[class_id]\n",
    "                    \n",
    "                    # Map to custom classes with person classification\n",
    "                    custom_class, is_vehicle, is_person = self.map_yolo_to_custom_classes(\n",
    "                        class_id, class_name, xyxy, frame\n",
    "                    )\n",
    "                    \n",
    "                    if custom_class:\n",
    "                        detection_data[custom_class] += 1\n",
    "                        detections.append({\n",
    "                            'class': custom_class,\n",
    "                            'bbox': [int(coord) for coord in xyxy],\n",
    "                            'confidence': float(confidence),\n",
    "                            'is_vehicle': is_vehicle,\n",
    "                            'is_person': is_person,\n",
    "                            'class_id': class_id,\n",
    "                            'original_class': class_name\n",
    "                        })\n",
    "        \n",
    "        detection_data['detections'] = detections\n",
    "        return detection_data\n",
    "    \n",
    "    def draw_detections(self, frame, detection_data):\n",
    "        \"\"\"Draw bounding boxes and labels on frame\"\"\"\n",
    "        for detection in detection_data.get('detections', []):\n",
    "            bbox = detection['bbox']\n",
    "            class_name = detection['class']\n",
    "            confidence = detection['confidence']\n",
    "            \n",
    "            color = self.colors.get(class_name, (255, 255, 255))\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "            \n",
    "            # Draw label with additional info for persons\n",
    "            if detection['is_person']:\n",
    "                label = f\"{class_name} {confidence:.2f}\"\n",
    "            else:\n",
    "                label = f\"{class_name} {confidence:.2f}\"\n",
    "            \n",
    "            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "            \n",
    "            # Label background\n",
    "            cv2.rectangle(frame, (bbox[0], bbox[1] - label_size[1] - 10),\n",
    "                         (bbox[0] + label_size[0], bbox[1]), color, -1)\n",
    "            \n",
    "            # Label text\n",
    "            cv2.putText(frame, label, (bbox[0], bbox[1] - 5),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def update_statistics(self, detection_data):\n",
    "        \"\"\"Update running statistics\"\"\"\n",
    "        self.frame_count += 1\n",
    "        \n",
    "        # Update vehicle statistics\n",
    "        for vehicle in self.vehicle_classes:\n",
    "            count = detection_data.get(vehicle, 0)\n",
    "            if count > 0:\n",
    "                self.detection_stats['vehicle_counts'][vehicle] += count\n",
    "                self.detection_stats['total_vehicles'] += count\n",
    "        \n",
    "        # Update person statistics\n",
    "        for person in self.person_classes:\n",
    "            count = detection_data.get(person, 0)\n",
    "            if count > 0:\n",
    "                self.detection_stats['person_counts'][person] += count\n",
    "                self.detection_stats['total_persons'] += count\n",
    "    \n",
    "    def display_statistics(self, frame, detection_data):\n",
    "        \"\"\"Display detection statistics on frame\"\"\"\n",
    "        stats_text = []\n",
    "        \n",
    "        # Current frame statistics\n",
    "        vehicle_count = sum(detection_data.get(cls, 0) for cls in self.vehicle_classes)\n",
    "        person_count = sum(detection_data.get(cls, 0) for cls in self.person_classes)\n",
    "        \n",
    "        stats_text.append(f\"Frame: {self.frame_count}\")\n",
    "        stats_text.append(f\"Current - Vehicles: {vehicle_count}, Persons: {person_count}\")\n",
    "        stats_text.append(\"---\")\n",
    "        \n",
    "        # Vehicle details\n",
    "        stats_text.append(\"Vehicles:\")\n",
    "        for vehicle in self.vehicle_classes:\n",
    "            count = detection_data.get(vehicle, 0)\n",
    "            if count > 0:\n",
    "                stats_text.append(f\"  {vehicle}: {count}\")\n",
    "        \n",
    "        # Person details\n",
    "        stats_text.append(\"Persons:\")\n",
    "        for person in self.person_classes:\n",
    "            count = detection_data.get(person, 0)\n",
    "            if count > 0:\n",
    "                stats_text.append(f\"  {person}: {count}\")\n",
    "        \n",
    "        # Running totals\n",
    "        stats_text.append(\"---\")\n",
    "        stats_text.append(f\"Total Vehicles: {self.detection_stats['total_vehicles']}\")\n",
    "        stats_text.append(f\"Total Persons: {self.detection_stats['total_persons']}\")\n",
    "        \n",
    "        # Draw statistics panel\n",
    "        y_offset = 30\n",
    "        panel_width = 300\n",
    "        \n",
    "        for i, text in enumerate(stats_text):\n",
    "            # Calculate text size\n",
    "            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n",
    "            panel_width = max(panel_width, text_size[0] + 20)\n",
    "            \n",
    "            # Draw background for text line\n",
    "            cv2.rectangle(frame, (10, y_offset - 20), (10 + panel_width, y_offset), \n",
    "                         (255, 255, 255), -1)\n",
    "            \n",
    "            # Draw text\n",
    "            cv2.putText(frame, text, (15, y_offset - 5),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "            y_offset += 25\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def print_detailed_statistics(self):\n",
    "        \"\"\"Print detailed statistics to console\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"DETECTION STATISTICS SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Total Frames Processed: {self.frame_count}\")\n",
    "        print(f\"Total Vehicles Detected: {self.detection_stats['total_vehicles']}\")\n",
    "        print(f\"Total Persons Detected: {self.detection_stats['total_persons']}\")\n",
    "        \n",
    "        print(\"\\nVehicle Breakdown:\")\n",
    "        for vehicle, count in self.detection_stats['vehicle_counts'].items():\n",
    "            if count > 0:\n",
    "                print(f\"  {vehicle}: {count}\")\n",
    "        \n",
    "        print(\"\\nPerson Breakdown:\")\n",
    "        for person, count in self.detection_stats['person_counts'].items():\n",
    "            if count > 0:\n",
    "                print(f\"  {person}: {count}\")\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    def run_detection(self):\n",
    "        \"\"\"Main function to run real-time detection\"\"\"\n",
    "        if not self.connect_to_camera():\n",
    "            return\n",
    "        \n",
    "        print(\"Starting real-time detection with person classification...\")\n",
    "        print(\"Press 'q' to quit, 'p' to pause, 's' for statistics\")\n",
    "        \n",
    "        paused = False\n",
    "        last_stat_time = 0\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                if not paused:\n",
    "                    ret, frame = self.cap.read()\n",
    "                    \n",
    "                    if not ret:\n",
    "                        print(\"Error reading frame. Attempting to reconnect...\")\n",
    "                        if not self.connect_to_camera():\n",
    "                            break\n",
    "                        continue\n",
    "                    \n",
    "                    # Process frame\n",
    "                    processed_frame, detection_data = self.process_frame(frame)\n",
    "                    \n",
    "                    # Display statistics on frame\n",
    "                    processed_frame = self.display_statistics(processed_frame, detection_data)\n",
    "                    \n",
    "                    # Show frame\n",
    "                    cv2.imshow('CCTV Vehicle and Person Detection', processed_frame)\n",
    "                    \n",
    "                    # Print periodic statistics to console\n",
    "                    current_time = cv2.getTickCount()\n",
    "                    if (current_time - last_stat_time) / cv2.getTickFrequency() > 10:  # Every 10 seconds\n",
    "                        self.print_detailed_statistics()\n",
    "                        last_stat_time = current_time\n",
    "                \n",
    "                # Handle key presses\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('p'):\n",
    "                    paused = not paused\n",
    "                    status = \"PAUSED\" if paused else \"RESUMED\"\n",
    "                    print(f\"Detection {status}\")\n",
    "                elif key == ord('s'):\n",
    "                    self.print_detailed_statistics()\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nDetection interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during detection: {e}\")\n",
    "        finally:\n",
    "            # Cleanup\n",
    "            if self.cap:\n",
    "                self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            # Print final statistics\n",
    "            self.print_detailed_statistics()\n",
    "            print(\"Detection stopped\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a3a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    # RTSP URL examples:\n",
    "    # rtsp://username:password@ip_address:port/stream\n",
    "    # rtsp://ip_address:554/stream\n",
    "    \n",
    "    # Replace with your actual RTSP URL\n",
    "    rtsp_url = \"rtsp://kumar:Kumar%23123@116.73.21.116:554/Streaming/channels/101\"\n",
    "    \n",
    "    # For testing with webcam (uncomment below)\n",
    "    #rtsp_url = 0\n",
    "    \n",
    "    # For testing with sample video file (uncomment below)\n",
    "    # rtsp_url = \"sample_video.mp4\"\n",
    "    \n",
    "    # Initialize detection system\n",
    "    detector = CCTVDetection(rtsp_url)\n",
    "    \n",
    "    try:\n",
    "        # Start detection\n",
    "        detector.run_detection()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
